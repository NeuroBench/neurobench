{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGm4fad3M-Sr"
   },
   "source": [
    "# Mackey Glass Benchmark Tutorial\n",
    "\n",
    "This tutorial aims to provide an insight on how the NeuroBench framework is organized and how you can use it to benchmark your own models!\n",
    "\n",
    "## About Mackey Glass:\n",
    "The Mackey Glass task is a chaotic function prediction task. Contrary to the other tasks in NeuroBench, the Mackey Glass dataset is synthetic. Real-world data can be high-dimensional and require large networks to achieve high accuracy, presenting challenges for solution types with limited I/O support and network capacity, such as mixed-signal prototype solutions. \n",
    "### Dataset:\n",
    "The Mackey Glass dataset is a one-dimensional non-linear time delay differential equation, where the evolution of the signal can be altered by a number of different parameters. \n",
    "<!-- $$ dx \\over dt = \\beta {x(t-\\tau)} \\over {1 + x(t-\\tau)^n} - \\gamma x(t)\n",
    "$$ -->\n",
    "$$ \\frac{dx}{dt} = \\frac{\\beta x(t-\\tau)}{1 + x(t-\\tau)^n} - \\gamma x(t) $$\n",
    "\n",
    "For the NeuroBench task, fourteen time series are generated from the Mackey Glass function, available at this link: https://huggingface.co/datasets/NeuroBench/mackey_glass. The time series vary by the $\\tau$ parameter from 17 to 30.\n",
    "\n",
    "### Benchmark Task:\n",
    "The task is a sequence-to-sequence prediction problem, similar to the non-human primate motor prediction task, which is also included in NeuroBench. The task involves predicting the next timestep value $f(t+\\Delta t)$, from the current value $f(t)$. Models are trained on the first half of the time series, during which the ground truth state $f(t)$ is provided to the model to make its prediction $f'(t+\\Delta t)$. During evaluation on the second half of the sequence, the model uses its prior prediction $f'(t)$ in order to generate each next value $f'(t+\\Delta t)$, autoregressively generating the second half of the time series.\n",
    "\n",
    "Symmetric mean absolute percentage error, sMAPE, is used to evaluate the correctness of the model's prediction. The length of the time series is dependent on Lyapunov time, which is listed with the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will import the relevant libraries. These include the dataset, model wrapper, and benchmark object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqtM6XbMM_hO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from neurobench.datasets import MackeyGlass\n",
    "from neurobench.models import TorchModel\n",
    "from neurobench.benchmarks import Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7HMjVPX7LZh"
   },
   "source": [
    "For this tutorial, we will make use an Echo State Network (ESN) model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0yYDNRZ7UxY"
   },
   "outputs": [],
   "source": [
    "# this is the network we will be using in this tutorial\n",
    "from examples.mackey_glass.echo_state_network import EchoStateNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTB808RoNXqL"
   },
   "source": [
    "Next, we load the hyperparameters of the ESN that were found using a random grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4jOfnt6OeIH"
   },
   "outputs": [],
   "source": [
    "esn_parameters = pd.read_csv(\"./model_data/echo_state_network_hyperparameters.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9doNsI0O0Jl"
   },
   "source": [
    "The Mackey Glass task contains 14 series with varying complexity. For simplicity, in this tutorial we only present with the first series, `tau=17`. The dataset is downloaded if it is not already available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDUczVTkPOsQ"
   },
   "outputs": [],
   "source": [
    "tau = 17\n",
    "# data in repo root dir\n",
    "file_path = \"../../../data/mackey_glass/mg_17.npy\"\n",
    "\n",
    "# Load data using the parameters loaded from the csv file\n",
    "mg = MackeyGlass(file_path = file_path)\n",
    "\n",
    "# Split test and train set\n",
    "train_set = Subset(mg, mg.ind_train)\n",
    "test_set = Subset(mg, mg.ind_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is treated such that each time series element is considered a separate sample. The sample is passed to the model, which predicts the next sample. The data is shaped as `[len_time_series, 1, 1]` in order to fit with the three dimensional data format standard of NeuroBench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = train_set[:]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model with the searched hyperparameters and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the hyperparamters for the current time-series\n",
    "ind_tau = esn_parameters.index[esn_parameters['tau'] == tau].tolist()[0]\n",
    "\n",
    "## Fitting Model ##\n",
    "# Load the model with the parameters loaded from esn_parameters\n",
    "esn = EchoStateNetwork(in_channels=1, \n",
    "    reservoir_size = esn_parameters['reservoir_size'][ind_tau], \n",
    "    input_scale = torch.tensor([esn_parameters['scale_bias'][ind_tau], esn_parameters['scale_input'][ind_tau],],dtype = torch.float64), \n",
    "    connect_prob = esn_parameters['connect_prob'][ind_tau], \n",
    "    spectral_radius = esn_parameters['spectral_radius'][ind_tau],\n",
    "    leakage = esn_parameters['leakage'][ind_tau], \n",
    "    ridge_param = esn_parameters['ridge_param'][ind_tau])\n",
    "\n",
    "esn.train()\n",
    "train_data, train_labels = train_set[:] # outputs (batch, 1, 1)\n",
    "warmup = 0.6 # in Lyapunov times\n",
    "warmup_pts = round(warmup*mg.pts_per_lyaptime)\n",
    "train_labels = train_labels[warmup_pts:]\n",
    "esn.fit(train_data, train_labels, warmup_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfRfdvXvOqRP"
   },
   "source": [
    "No pre- or post-processors are used in this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GHY8vTROwzP"
   },
   "outputs": [],
   "source": [
    "preprocessors = []\n",
    "postprocessors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next specify the metrics to calculate. For this task, sMAPE is used to evaluate correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_metrics = [\"footprint\", \"connection_sparsity\"]\n",
    "workload_metrics = [\"sMAPE\", \"activation_sparsity\", \"synaptic_operations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ytLJ-dUPp0b"
   },
   "source": [
    "The test set is wrapped in a DataLoader. Importantly, shuffle should be False, since the samples of the time series should be passed in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ldww7kiYPsU2"
   },
   "outputs": [],
   "source": [
    "test_set_loader = DataLoader(test_set, batch_size=mg.testtime_pts, shuffle=False)\n",
    "\n",
    "# Wrap the model\n",
    "model = TorchModel(esn)\n",
    "\n",
    "benchmark = Benchmark(model, test_set_loader, [], [], [static_metrics, workload_metrics]) \n",
    "results = benchmark.run()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected results:\n",
    "{'footprint': 7488448, 'connection_sparsity': 0.0297, 'sMAPE': 10.893483007394062, 'activation_sparsity': 0.0, 'synaptic_operations': {'Effective_MACs': 908294.0, 'Effective_ACs': 0.0, 'Dense': 936056.0}}\n",
    "\n",
    "Note that due to the ESN fit functionality being dependent on lower-level arithmetic libraries, your results may be different on a different machine."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
