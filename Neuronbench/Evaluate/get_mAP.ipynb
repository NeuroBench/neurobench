{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('/home/shenqi/Master_thesis')\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "from Neuronbench.utils.models import Vanilla\n",
    "from Neuronbench.utils.dataset import seq_dataloader\n",
    "\n",
    "from metavision_ml.detection.anchors import Anchors\n",
    "from metavision_ml.detection.rpn import BoxHead\n",
    "from metavision_ml.data import box_processing as box_api\n",
    "from metavision_ml.detection.losses import DetectionLoss\n",
    "from metavision_ml.metrics.coco_eval import CocoEvaluator\n",
    "from metavision_sdk_core import EventBbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = seq_dataloader()\n",
    "model = Vanilla(cin = dataloader.in_channels, cout = 256, base = 16)\n",
    "box_coder = Anchors(num_levels=model.levels, anchor_list=\"PSEE_ANCHORS\", variances=[0.1, 0.2])\n",
    "head = BoxHead(model.cout, box_coder.num_anchors, len(dataloader.wanted_keys) + 1, 0)\n",
    "model = model.to('cuda')\n",
    "head = head.to('cuda')\n",
    "model.load_state_dict(torch.load('../train_RED/save_models/25_model.pth',map_location=torch.device('cuda')))\n",
    "head.load_state_dict(torch.load('../train_RED/save_models/25_pd.pth',map_location=torch.device('cuda')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_predictions(preds, targets, video_infos, frame_is_labeled,skip_us):\n",
    "       \n",
    "        dt_detections = {}\n",
    "        gt_detections = {}\n",
    "        for t in range(len(targets)):\n",
    "            for i in range(len(targets[t])):\n",
    "                gt_boxes = targets[t][i]\n",
    "                pred = preds[t][i]\n",
    "\n",
    "                video_info, tbin_start, _ = video_infos[i]\n",
    "\n",
    "                if video_info.padding or frame_is_labeled[t, i] == False:\n",
    "                    continue\n",
    "\n",
    "                name = video_info.path\n",
    "                if name not in dt_detections:\n",
    "                    dt_detections[name] = [np.zeros((0), dtype=box_api.EventBbox)]\n",
    "                if name not in gt_detections:\n",
    "                    gt_detections[name] = [np.zeros((0), dtype=box_api.EventBbox)]\n",
    "                assert video_info.start_ts == 0\n",
    "                ts = tbin_start + t * video_info.delta_t\n",
    "\n",
    "                if ts < skip_us:\n",
    "                    continue\n",
    "\n",
    "                if isinstance(gt_boxes, torch.Tensor):\n",
    "                    gt_boxes = gt_boxes.cpu().numpy()\n",
    "                if gt_boxes.dtype == np.float32:\n",
    "                    gt_boxes = box_api.box_vectors_to_bboxes(gt_boxes[:, :4], gt_boxes[:, 4], ts=ts)\n",
    "\n",
    "                if pred['boxes'] is not None and len(pred['boxes']) > 0:\n",
    "                    boxes = pred['boxes'].cpu().data.numpy()\n",
    "                    labels = pred['labels'].cpu().data.numpy()\n",
    "                    scores = pred['scores'].cpu().data.numpy()\n",
    "                    dt_boxes = box_api.box_vectors_to_bboxes(boxes, labels, scores, ts=ts)\n",
    "                    dt_detections[name].append(dt_boxes)\n",
    "                else:\n",
    "                    dt_detections[name].append(np.zeros((0), dtype=EventBbox))\n",
    "\n",
    "                if len(gt_boxes):\n",
    "                    gt_boxes[\"t\"] = ts\n",
    "                    gt_detections[name].append(gt_boxes)\n",
    "                else:\n",
    "                    gt_detections[name].append(np.zeros((0), dtype=EventBbox))\n",
    "\n",
    "        return dt_detections, gt_detections\n",
    "\n",
    "def inference_epoch_end(outputs):\n",
    "    \n",
    "    print('==> Start evaluation')\n",
    "    dt_detections = defaultdict(list)\n",
    "    gt_detections = defaultdict(list)\n",
    "\n",
    "    for item in outputs:\n",
    "        for k, v in item['gt'].items():\n",
    "            gt_detections[k].extend(v)\n",
    "        for k, v in item['dt'].items():\n",
    "            dt_detections[k].extend(v)\n",
    "\n",
    "    evaluator = CocoEvaluator(classes=['background'] + dataloader.wanted_keys, height=dataloader.height, width=dataloader.width)\n",
    "    for key in gt_detections:\n",
    "        evaluator.partial_eval([np.concatenate(gt_detections[key])], [np.concatenate(dt_detections[key])])\n",
    "    coco_kpi = evaluator.accumulate()\n",
    "    return coco_kpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_val_list = []\n",
    "with tqdm(total=len(dataloader.seq_dataloader_test), desc=f'Testing',ncols=120) as pbar:\n",
    "    for data in dataloader.seq_dataloader_test:\n",
    "        pbar.update(1)\n",
    "        inputs = data['inputs'].to(device='cuda')\n",
    "        with torch.no_grad():\n",
    "            feature = model(inputs)\n",
    "            loc_preds_val, cls_preds_val = head(feature)\n",
    "            scores = head.get_scores(cls_preds_val)\n",
    "            scores = scores.to('cpu')\n",
    "            for i, feat in enumerate(feature):\n",
    "                feature[i] = feature[i].to('cpu')\n",
    "            inputs = data['inputs'].to('cpu')\n",
    "            loc_preds_val = loc_preds_val.to('cpu')\n",
    "            preds = box_coder.decode(feature, inputs, loc_preds_val, scores, batch_size=inputs.shape[1], score_thresh=0.05,\n",
    "                        nms_thresh=0.5, max_boxes_per_input=500)\n",
    "            # print(preds)\n",
    "            dt_dic, gt_dic = accumulate_predictions(preds, data[\"labels\"], data[\"video_infos\"], data[\"frame_is_labeled\"], 500000)\n",
    "            output_val_list.append({'dt': dt_dic, 'gt': gt_dic})\n",
    "    coco_val_result = inference_epoch_end(output_val_list)\n",
    "    print(coco_val_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_torch1_13_cu117",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
