{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyNLu56m20JM"
   },
   "source": [
    "# **Neuromorphic Human Activity Recognition (NeHAR) task**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1yo7vAs8z3n"
   },
   "source": [
    "In this notebook we benchmarked SNN-based models performing the Neuromorphic Human Activity Recognition (NeHAR) task using IMU sensor data acquired form a commercial smartwatch.\n",
    "\n",
    "Human Activity Recognition (HAR) is a time-dependent task that has applications in various aspects of human life, from healthcare to sports, safety, and smart environments. In this task, we present a comparative analysis of different SNN-based models designed for classifying raw signals (Accelerometer and Gyroscope) collected in the Wireless Sensor Data Mining (WISDM) dataset.\n",
    "\n",
    "The WISDM dataset consists of data from 51 subjects performing 18 activities. This dataset collects signals from both the accelerometer and the gyroscope of a smartphone and a smartwatch. Each activity is recorded for 3 minutes with an acquisition rate of 20 Hz. The dataset's classes are balanced, with each activity represented in the dataset contributing approximately 5.3% to 5.8% of the total approximately 15.63 million samples.\n",
    "From the whole smartwatch dataset, we selected a subset of general hand-oriented activities for our analysis. These activities include: (1) dribbling in basketball, (2) playing catch with a tennis ball, (3) typing, (4) writing, (5) clapping, (6) brushing teeth, and (7) folding clothes. We divided the signals into non-overlapping temporal windows with a length of 2 seconds. These temporal windows serve as the input layer for the benchmarked models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zt1kUxe6c_-s"
   },
   "source": [
    "---\n",
    "\n",
    "Refferring to the paper: Fra, V., Forno, E., Pignari, R., Stewart, T. C., Macii, E., & Urgese, G. (2022).\n",
    "***Human activity recognition: suitability of a neuromorphic approach for on-edge AIoT applications. Neuromorphic Computing and Engineering***, 2(1), 014006.\n",
    "DOI ***10.1088/2634-4386/ac4c38***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJsVu0H2FIol"
   },
   "source": [
    "## Environment set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuyCkI5mB1Qc"
   },
   "source": [
    "### Install packages in the Google Colab runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-qowl4U2xh2"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gdown\n",
    "!pip install hyperopt\n",
    "!pip install matplotlib\n",
    "!pip install neurobench\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install scipy\n",
    "!pip install seaborn\n",
    "!pip install snntorch\n",
    "!pip install torch\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc4eYiEoCchd"
   },
   "source": [
    "### Basic import\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HiLoKFukCfHl",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import random\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from neurobench.models import SNNTorchModel\n",
    "from neurobench.postprocessing.postprocessor import aggregate, choose_max_count\n",
    "from neurobench.benchmarks import Benchmark\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0pq1QdFDEH9"
   },
   "source": [
    "### Utility functions and general settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hNEkKo98DGXk"
   },
   "outputs": [],
   "source": [
    "def create_directory(\n",
    "    directory_path\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Muller-Cleve, Simon F.; Istituto Italiano di Tecnologia - IIT; Event-driven perception in robotics - EDPR; Genova, Italy.\n",
    "    \"\"\"\n",
    "    if os.path.exists(directory_path):\n",
    "        return None\n",
    "    else:\n",
    "        try:\n",
    "            os.makedirs(directory_path)\n",
    "        except:\n",
    "            return None\n",
    "        return directory_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fuQay3IDEPMl"
   },
   "outputs": [],
   "source": [
    "use_seed = True\n",
    "\n",
    "if use_seed:\n",
    "    seed = 42\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "else:\n",
    "    seed = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQga4Aa7HaM1"
   },
   "source": [
    "## Import HAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_pZK3qVd6erR"
   },
   "outputs": [],
   "source": [
    "### Link to the folder with data\n",
    "folder_link = \"https://drive.google.com/drive/folders/15TSYpE5QSzjOoqvOn8f7Wf59MwhqQEkB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0l0NUOX6XjC"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "if \"data\" not in os.listdir(\"/\"):\n",
    "  ! gdown $folder_link -O ./data --folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7McG954n64Ii"
   },
   "outputs": [],
   "source": [
    "ds_train = torch.load(\"./data/watch_subset2_40_ds_train.pt\", map_location=device)\n",
    "ds_val = torch.load(\"./data/watch_subset2_40_ds_val.pt\", map_location=device)\n",
    "ds_test = torch.load(\"./data/watch_subset2_40_ds_test.pt\", map_location=device)\n",
    "\n",
    "act_map = {\n",
    "    'A': 'walking',\n",
    "    'B': 'jogging',\n",
    "    'C': 'stairs',\n",
    "    'D': 'sitting',\n",
    "    'E': 'standing',\n",
    "    'M': 'kicking',\n",
    "    'P': 'dribbling',\n",
    "    'O': 'catch',\n",
    "    'F': 'typing',\n",
    "    'Q': 'writing',\n",
    "    'R': 'clapping',\n",
    "    'G': 'teeth',\n",
    "    'S': 'folding',\n",
    "    'J': 'pasta',\n",
    "    'H': 'soup',\n",
    "    'L': 'sandwich',\n",
    "    'I': 'chips',\n",
    "    'K': 'drinking',\n",
    "}\n",
    "\n",
    "labels_mapping = {k:act_map[k] for k in list(act_map.keys())[6:13] if k in act_map}\n",
    "labels_activity = list(act_map.values())[6:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ft_EYrM08PwK"
   },
   "outputs": [],
   "source": [
    "# Extract a random sample from the training set\n",
    "random_sample = next(iter(DataLoader(ds_train, batch_size=1, shuffle=False)))\n",
    "random_data = random_sample[0]\n",
    "random_label = random_sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nuRIrdBU9Uci"
   },
   "outputs": [],
   "source": [
    "# Randomly select a channel from IMU data\n",
    "rnd_ch = np.random.randint(0,6)\n",
    "print(\"Selected sample: {}\".format(labels_activity[random_label]))\n",
    "print(\"Selected channel: {}\\n\".format(rnd_ch))\n",
    "\n",
    "random_ch = random_data[0,:,rnd_ch]\n",
    "print(\"IMU values in time for the selected sample and channel:\")\n",
    "random_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pq8kEA4fI312"
   },
   "outputs": [],
   "source": [
    "# Plot the random (original) example\n",
    "plt.figure(figsize=(8,4.5))\n",
    "plt.plot(random_ch.cpu().numpy())\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"IMU data (a.u.)\")\n",
    "plt.title(\"Activity: {}\".format(labels_activity[random_label]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQOTbR0zJ7N2"
   },
   "outputs": [],
   "source": [
    "print(\"Training set \\t ---data---\\n \\tnumber of samples: {}\\n \\tsample shape: {}\".format(\n",
    "    len(ds_train),next(iter(DataLoader(ds_train, batch_size=1, shuffle=False)))[0].shape))\n",
    "print(\"Training set \\t ---labels---\\n \\tnumber of labels: {}\\n \\tlabel shape: {}\".format(\n",
    "    len(ds_train),next(iter(DataLoader(ds_train, batch_size=1, shuffle=False)))[1].shape))\n",
    "print(\"\\n\")\n",
    "print(\"Validation set \\t ---data---\\n \\tnumber of samples: {}\\n \\tshape: {}\".format(\n",
    "    len(ds_val),next(iter(DataLoader(ds_val, batch_size=1, shuffle=False)))[0].shape))\n",
    "print(\"Validation set \\t ---labels---\\n \\tnumber of labels: {}\\n \\tlabel shape: {}\".format(\n",
    "    len(ds_val),next(iter(DataLoader(ds_val, batch_size=1, shuffle=False)))[1].shape))\n",
    "print(\"\\n\")\n",
    "print(\"Test set \\t ---data---\\n \\tnumber of samples: {}\\n \\tshape: {}\".format(\n",
    "    len(ds_test),next(iter(DataLoader(ds_test, batch_size=1, shuffle=False)))[0].shape))\n",
    "print(\"Test set \\t ---labels---\\n \\tnumber of labels: {}\\n \\tlabel shape: {}\".format(\n",
    "    len(ds_test),next(iter(DataLoader(ds_test, batch_size=1, shuffle=False)))[1].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZISpcrO3JUGv"
   },
   "source": [
    "## Feedforward SNN\n",
    "\n",
    "Training, Validation and Test of a FFSNN fully-connected\n",
    "\n",
    "*Adapted from: V. Fra et al.; \"Neuromorphic Human Activity Recognition through LIF-based neurons\"; Brain-Inspired Computing Workshop 2023, Modena (Italy)*\n",
    "\n",
    "\n",
    "Neurobench Metrics extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ll5LquQfyim9"
   },
   "outputs": [],
   "source": [
    "def training_loop(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    net,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    device):\n",
    "    \"\"\"\n",
    "    Fra, Vittorio; Politecnico di Torino; EDA Group; Torino, Italy.\n",
    "    \"\"\"\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "    batch_loss = []\n",
    "    batch_acc = []\n",
    "\n",
    "    for data, labels in tqdm(train_loader):\n",
    "\n",
    "      data = data.to(device)#.swapaxes(1, 0)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      net.train()\n",
    "      rec = net.single_forward(data)\n",
    "      spk_rec = rec[0]\n",
    "\n",
    "      # Training loss\n",
    "      loss_val = loss_fn(spk_rec, labels)\n",
    "      batch_loss.append(loss_val.detach().cpu().item())\n",
    "\n",
    "      # Training accuracy\n",
    "      act_total_out = torch.sum(spk_rec, 0)  # sum over time\n",
    "      _, neuron_max_act_total_out = torch.max(act_total_out, 1)  # argmax over output units to compare to labels\n",
    "      batch_acc.append(np.mean((neuron_max_act_total_out == labels).detach().cpu().numpy()))\n",
    "\n",
    "      # Gradient calculation + weight update\n",
    "      optimizer.zero_grad()\n",
    "      loss_val.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    epoch_loss = np.mean(batch_loss)\n",
    "    epoch_acc = np.mean(batch_acc)\n",
    "\n",
    "    return [epoch_loss, epoch_acc]\n",
    "\n",
    "\n",
    "def val_test_loop(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    net,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    shuffle=True,\n",
    "    label_probabilities=False,\n",
    "    return_spikes=False):\n",
    "    \"\"\"\n",
    "    Fra, Vittorio; Politecnico di Torino; EDA Group; Torino, Italy.\n",
    "    \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "      net.eval()\n",
    "\n",
    "      loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=False)\n",
    "\n",
    "      batch_loss = []\n",
    "      batch_acc = []\n",
    "\n",
    "      for data, labels in tqdm(loader):\n",
    "          data = data.to(device)#.swapaxes(1, 0)\n",
    "          labels = labels.to(device)\n",
    "\n",
    "          rec = net.single_forward(data)\n",
    "          spk_out = rec[0]\n",
    "\n",
    "          # Loss\n",
    "          loss_val = loss_fn(spk_out, labels)\n",
    "          batch_loss.append(loss_val.detach().cpu().item())\n",
    "\n",
    "          # Accuracy\n",
    "          act_total_out = torch.sum(spk_out, 0)  # sum over time\n",
    "          _, neuron_max_act_total_out = torch.max(act_total_out, 1)  # argmax over output units to compare to labels\n",
    "          batch_acc.append(np.mean((neuron_max_act_total_out == labels).detach().cpu().numpy()))\n",
    "\n",
    "      if label_probabilities:\n",
    "          log_softmax_fn = nn.LogSoftmax(dim=-1)\n",
    "          log_p_y = log_softmax_fn(act_total_out)\n",
    "          if return_spikes:\n",
    "            return [np.mean(batch_loss), np.mean(batch_acc)], torch.exp(log_p_y), spk_out.detach().cpu().numpy()\n",
    "          else:\n",
    "            return [np.mean(batch_loss), np.mean(batch_acc)], torch.exp(log_p_y)\n",
    "      else:\n",
    "        if return_spikes:\n",
    "          return [np.mean(batch_loss), np.mean(batch_acc)], spk_out.detach().cpu().numpy()\n",
    "        else:\n",
    "          return [np.mean(batch_loss), np.mean(batch_acc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrnyIv-LWg0W"
   },
   "outputs": [],
   "source": [
    "settings= {\"enc_pop\": 32,\n",
    "           \"nb_hidden\": 250,\n",
    "           \"beta_hid\": 0.7,\n",
    "           \"beta_out\": 0.65,\n",
    "           \"beta_enc\": 0.2,\n",
    "           \"alpha_hid\": 0.55,\n",
    "           \"alpha_out\": 0.9,\n",
    "           \"thr_enc\": 0.5,\n",
    "           \"thr_hid\": 0.7,\n",
    "           \"thr_out\": 0.9,\n",
    "           \"lr\": 0.0001,\n",
    "           \"batch_size\": 64\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUe597nFyim9"
   },
   "outputs": [],
   "source": [
    "network_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3kuATbQJWOv"
   },
   "outputs": [],
   "source": [
    "### Network structure (input data --> encoding -> hidden -> output)\n",
    "input_enc = 6\n",
    "output_enc = int(settings[\"enc_pop\"])\n",
    "num_hidden = int(settings[\"nb_hidden\"])\n",
    "num_outputs = 7\n",
    "\n",
    "num_steps = 40\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    ##### Initialize layers #####\n",
    "    ### Encoding layer\n",
    "    self.enc = nn.Linear(input_enc, output_enc)\n",
    "    self.s_enc = snn.Leaky(beta=settings['beta_enc'], threshold=settings['thr_enc'])\n",
    "    ### Hidden layer\n",
    "    self.fc1 = nn.Linear(output_enc, num_hidden)\n",
    "    self.s1 = snn.Synaptic(beta=settings['beta_hid'], alpha=settings['alpha_hid'], threshold=settings['thr_hid'])\n",
    "    ### Output layer\n",
    "    self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "    self.s2 = snn.Synaptic(beta=settings['beta_out'], alpha=settings['alpha_out'], threshold=settings['thr_out'])\n",
    "    self.mem_enc = self.s_enc.init_leaky()\n",
    "    ### Hidden layer\n",
    "    self.syn1, self.mem1 = self.s1.init_synaptic()\n",
    "    ### Output layer\n",
    "    self.syn2, self.mem2 = self.s2.init_synaptic()\n",
    "\n",
    "  def single_forward(self, x):\n",
    "\n",
    "    ### Encoding layer\n",
    "    mem_enc = self.s_enc.init_leaky()\n",
    "    ### Hidden layer\n",
    "    syn1, mem1 = self.s1.init_synaptic()\n",
    "    ### Output layer\n",
    "    syn2, mem2 = self.s2.init_synaptic()\n",
    "\n",
    "    # Record the final layer\n",
    "    spk2_rec = []\n",
    "    syn2_rec = []\n",
    "    mem2_rec = []\n",
    "\n",
    "    for step in range(num_steps):\n",
    "      ### Encoding layer\n",
    "      cur_enc = self.enc(x[:,step])\n",
    "      spk_enc, mem_enc = self.s_enc(cur_enc, mem_enc)\n",
    "      ### Hidden layer\n",
    "      cur1 = self.fc1(spk_enc)\n",
    "      spk1, syn1, mem1 = self.s1(cur1, syn1, mem1)\n",
    "      ### Output layer\n",
    "      cur2 = self.fc2(spk1)\n",
    "      spk2, syn2, mem2 = self.s2(cur2, syn2, mem2)\n",
    "\n",
    "      spk2_rec.append(spk2)\n",
    "      syn2_rec.append(syn2)\n",
    "      mem2_rec.append(mem2)\n",
    "\n",
    "    return torch.stack(spk2_rec, dim=0), torch.stack(syn2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    "\n",
    "  def forward(self, x):\n",
    "       ### Encoding layer\n",
    "      cur_enc = self.enc(x)\n",
    "      spk_enc, self.mem_enc = self.s_enc(cur_enc, self.mem_enc)\n",
    "      ### Hidden layer\n",
    "      cur1 = self.fc1(spk_enc)\n",
    "      spk1, self.syn1, self.mem1 = self.s1(cur1, self.syn1, self.mem1)\n",
    "      ### Output layer\n",
    "      cur2 = self.fc2(spk1)\n",
    "      spk2, self.syn2, self.mem2 = self.s2(cur2, self.syn2, self.mem2)\n",
    "\n",
    "      return spk2, self.mem2\n",
    "\n",
    "  def reset(self):\n",
    "    self.mem_enc = self.s_enc.init_leaky()\n",
    "    ### Hidden layer\n",
    "    self.syn1, self.mem1 = self.s1.init_synaptic()\n",
    "    ### Output layer\n",
    "    self.syn2, self.mem2 = self.s2.init_synaptic()\n",
    "\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STet-LLUN6ov"
   },
   "outputs": [],
   "source": [
    "### Set the loss function\n",
    "loss_fn = SF.ce_count_loss()\n",
    "\n",
    "### Set the optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=settings['lr'], betas=(0.9, 0.999))\n",
    "\n",
    "### Set the batch size\n",
    "batch_size = settings[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPfOJW8bPV1A"
   },
   "source": [
    "#### Training (with validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DBFQPlh_yim-"
   },
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Xst_Q5xPLjg"
   },
   "outputs": [],
   "source": [
    "training_results = []\n",
    "validation_results = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "  train_loss, train_acc = training_loop(ds_train, batch_size, net, optimizer, loss_fn, device)\n",
    "  val_loss, val_acc = val_test_loop(ds_val, batch_size, net, loss_fn, device)\n",
    "\n",
    "  training_results.append([train_loss, train_acc])\n",
    "  validation_results.append([val_loss, val_acc])\n",
    "\n",
    "  print(\"Epoch {}/{}: \\n\\ttraining loss: {} \\n\\tvalidation loss: {} \\n\\ttraining accuracy: {}% \\n\\tvalidation accuracy: {}%\".format(epoch+1, num_epochs, training_results[-1][0], validation_results[-1][0], np.round(training_results[-1][1]*100,4), np.round(validation_results[-1][1]*100,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKpsa5FUPaDX"
   },
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DQhZw0YPbZY"
   },
   "outputs": [],
   "source": [
    "test_results, lbl_probs, spk_out = val_test_loop(ds_test, batch_size, net, loss_fn, device, label_probabilities=True, return_spikes=True)\n",
    "\n",
    "print(\"\\nTest accuracy: {}%\".format(np.round(test_results[1]*100,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUEEnask2qnk"
   },
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvWjUi8j2ev3"
   },
   "outputs": [],
   "source": [
    "create_directory('model_data')\n",
    "torch.save(net.state_dict(), './model_data/HAR_FFSNN.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGVwG0kmHBn9"
   },
   "source": [
    "#### Neurobench Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJqwmLeFG_Po"
   },
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "net.load_state_dict(torch.load('./model_data/HAR_FFSNN.pth'))\n",
    "\n",
    "model = SNNTorchModel(net)\n",
    "test_set_loader = DataLoader(ds_test, batch_size=settings[\"batch_size\"], shuffle=True, drop_last=False)\n",
    "postprocessors = [choose_max_count]\n",
    "\n",
    "static_metrics = [\"model_size\"]\n",
    "workload_metrics = [\"classification_accuracy\"]\n",
    "\n",
    "benchmark = Benchmark(model, test_set_loader, [], postprocessors, [static_metrics, workload_metrics])\n",
    "results = benchmark.run()\n",
    "print(results)\n",
    "\n",
    "results = [results[key] for key in results.keys()]\n",
    "results.insert(0, 'FFSNN')\n",
    "\n",
    "network_results.append(copy.copy(results))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ztuHhcAwzz0"
   },
   "source": [
    "#### Single-sample inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urOgz_rIsyew"
   },
   "outputs": [],
   "source": [
    "single_sample = next(iter(DataLoader(ds_test, batch_size=1, shuffle=True)))\n",
    "print(\"Randomly selected sample: {}\".format(labels_activity[single_sample[1].cpu()[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZcLZrrmuple"
   },
   "outputs": [],
   "source": [
    "### Inference\n",
    "_, lbl_probs, spk_out = val_test_loop(TensorDataset(single_sample[0],single_sample[1]), 1, net, loss_fn, device, label_probabilities=True, return_spikes=True)\n",
    "\n",
    "### Plot output spiking activity\n",
    "spk_out = np.moveaxis(spk_out,1,2)\n",
    "spk_out = np.squeeze(spk_out, axis=-1)\n",
    "spk_out.shape\n",
    "aer = []\n",
    "for num,el in enumerate(spk_out):\n",
    "  addr = np.where(el)[0].tolist()\n",
    "  if len(addr) > 0:\n",
    "    for ii in addr:\n",
    "      aer.append([num,ii])\n",
    "aer = np.array(aer)\n",
    "plt.scatter(aer[:,0], aer[:,1], s=1)\n",
    "plt.xlabel(\"Time step (a.u.)\")\n",
    "plt.ylabel(\"Neuron\")\n",
    "plt.title(\"Spiking output activity (activity: {}, prediction: {})\".format(labels_activity[single_sample[1].cpu()[0]],labels_activity[np.argmax(lbl_probs.cpu())]))\n",
    "plt.ylim(-0.5,6.5)\n",
    "plt.xlim((-0.5,num_steps+0.5))\n",
    "plt.yticks(range(7),labels_activity)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLabels probabilities:\")\n",
    "for num,el in enumerate(labels_activity):\n",
    "  print(\"\\t{} \\n\\t\\t{}%\".format(el,np.round(lbl_probs.cpu().numpy()[0][num]*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33yYb13Lyim_"
   },
   "source": [
    "## Recurrent SNN\n",
    "\n",
    "Training, Validation and Test of a fully-connected RSNN\n",
    "\n",
    "*Adapted from: V. Fra et al.; \"Neuromorphic Human Activity Recognition through LIF-based neurons\"; Brain-Inspired Computing Workshop 2023, Modena (Italy)*\n",
    "\n",
    "\n",
    "Neurobench Metrics extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDRe_QPAyim_"
   },
   "outputs": [],
   "source": [
    "def training_loop(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    net,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    device):\n",
    "    \"\"\"\n",
    "    Fra, Vittorio; Politecnico di Torino; EDA Group; Torino, Italy.\n",
    "    \"\"\"\n",
    "\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "    batch_loss = []\n",
    "    batch_acc = []\n",
    "\n",
    "    for data, labels in tqdm(train_loader):\n",
    "\n",
    "      data = data.to(device)#.swapaxes(1, 0)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      net.train()\n",
    "      rec = net.single_forward(data)\n",
    "      spk_rec = rec[0]\n",
    "\n",
    "      # Training loss\n",
    "      loss_val = loss_fn(spk_rec, labels)\n",
    "      batch_loss.append(loss_val.detach().cpu().item())\n",
    "\n",
    "      # Training accuracy\n",
    "      act_total_out = torch.sum(spk_rec, 0)  # sum over time\n",
    "      _, neuron_max_act_total_out = torch.max(act_total_out, 1)  # argmax over output units to compare to labels\n",
    "      batch_acc.append(np.mean((neuron_max_act_total_out == labels).detach().cpu().numpy()))\n",
    "\n",
    "      # Gradient calculation + weight update\n",
    "      optimizer.zero_grad()\n",
    "      loss_val.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    epoch_loss = np.mean(batch_loss)\n",
    "    epoch_acc = np.mean(batch_acc)\n",
    "\n",
    "    return [epoch_loss, epoch_acc]\n",
    "\n",
    "\n",
    "def val_test_loop(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    net,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    shuffle=True,\n",
    "    label_probabilities=False,\n",
    "    return_spikes=False):\n",
    "    \"\"\"\n",
    "    Fra, Vittorio; Politecnico di Torino; EDA Group; Torino, Italy.\n",
    "    \"\"\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "      net.eval()\n",
    "\n",
    "      loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=False)\n",
    "\n",
    "      batch_loss = []\n",
    "      batch_acc = []\n",
    "\n",
    "      for data, labels in tqdm(loader):\n",
    "          data = data.to(device)#.swapaxes(1, 0)\n",
    "          labels = labels.to(device)\n",
    "\n",
    "          rec = net.single_forward(data)\n",
    "          spk_out = rec[0]\n",
    "\n",
    "          # Loss\n",
    "          loss_val = loss_fn(spk_out, labels)\n",
    "          batch_loss.append(loss_val.detach().cpu().item())\n",
    "\n",
    "          # Accuracy\n",
    "          act_total_out = torch.sum(spk_out, 0)  # sum over time\n",
    "          _, neuron_max_act_total_out = torch.max(act_total_out, 1)  # argmax over output units to compare to labels\n",
    "          batch_acc.append(np.mean((neuron_max_act_total_out == labels).detach().cpu().numpy()))\n",
    "\n",
    "      if label_probabilities:\n",
    "          log_softmax_fn = nn.LogSoftmax(dim=-1)\n",
    "          log_p_y = log_softmax_fn(act_total_out)\n",
    "          if return_spikes:\n",
    "            return [np.mean(batch_loss), np.mean(batch_acc)], torch.exp(log_p_y), spk_out.detach().cpu().numpy()\n",
    "          else:\n",
    "            return [np.mean(batch_loss), np.mean(batch_acc)], torch.exp(log_p_y)\n",
    "      else:\n",
    "        if return_spikes:\n",
    "          return [np.mean(batch_loss), np.mean(batch_acc)], spk_out.detach().cpu().numpy()\n",
    "        else:\n",
    "          return [np.mean(batch_loss), np.mean(batch_acc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1CUIEFEfyim_"
   },
   "outputs": [],
   "source": [
    "settings = {\"neurons_per_pop\": 5.0,\n",
    "            \"output_pop\": 32.0,\n",
    "            \"nb_hidden\": 250.0,\n",
    "            \"alpha_hid\": 0.55,\n",
    "            \"alpha_out\": 0.9,\n",
    "            \"beta_hid\": 0.7,\n",
    "            \"beta_out\": 0.65,\n",
    "            \"beta_enc\": 0.2,\n",
    "            \"lr\": 0.0001,\n",
    "            \"slope\": 15.0,\n",
    "            \"batch_size\": 64.0\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEre927Lyim_"
   },
   "outputs": [],
   "source": [
    "### Network structure (input data --> encoding -> hidden -> output)\n",
    "input_channels = 6\n",
    "pop_size = int(settings[\"neurons_per_pop\"]) # --> the number of neurons for the encoding layer with populations will be: pop_size*input_channels\n",
    "output_pop = int(settings[\"output_pop\"])\n",
    "output_enc = output_pop*input_channels\n",
    "num_hidden = int(settings[\"nb_hidden\"])\n",
    "num_outputs = 7\n",
    "\n",
    "num_steps = 40\n",
    "\n",
    "### Surrogate gradient setting\n",
    "spike_grad = surrogate.fast_sigmoid(slope=int(settings[\"slope\"]))\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        ##### Define layers #####\n",
    "        ### Encoding layer with populations\n",
    "        self.pop_size = pop_size\n",
    "        self.enc_pops = []\n",
    "        self.lif_enc_pops = []\n",
    "        for ii in range(input_channels):\n",
    "            self.enc_pops.append(nn.Linear(pop_size, output_pop).to(device))\n",
    "            self.lif_enc_pops.append(snn.Leaky(beta=settings[\"beta_enc\"], learn_beta=True, learn_threshold=True).to(device))\n",
    "        self.enc_pops = nn.ModuleList(self.enc_pops)\n",
    "        self.lif_enc_pops = nn.ModuleList(self.lif_enc_pops)\n",
    "        ### Recurrent layer\n",
    "        self.fc1 = nn.Linear(output_enc, num_hidden)\n",
    "        self.lif1 = snn.RSynaptic(alpha=settings[\"alpha_hid\"], beta=settings[\"beta_hid\"], learn_alpha=True, learn_beta=True, learn_threshold=True, linear_features=num_hidden, spike_grad=spike_grad)\n",
    "        ### Output layer\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif2 = snn.Synaptic(alpha=settings[\"alpha_out\"], beta=settings[\"beta_out\"], learn_alpha=True, learn_beta=True, learn_threshold=True)\n",
    "\n",
    "        # NOTE that this is actually redundant outside of NeuroBench benchmarking\n",
    "        ##### Initialize hidden states at t=0 #####\n",
    "        ### Encoding layer with populations\n",
    "        self.mem_pops_enc = torch.empty((input_channels,int(settings[\"batch_size\"]),output_pop), dtype=torch.float, device=device)\n",
    "        self.spk_pops_enc = torch.empty((input_channels,int(settings[\"batch_size\"]),output_pop), dtype=torch.float, device=device)\n",
    "        self.cur_pops_enc = torch.empty((input_channels,int(settings[\"batch_size\"]),output_pop), dtype=torch.float, device=device)\n",
    "        ### Recurrent layer\n",
    "        self.spk1, self.syn1, self.mem1 = self.lif1.init_rsynaptic()\n",
    "        ### Output layer\n",
    "        self.syn2, self.mem2 = self.lif2.init_synaptic()\n",
    "\n",
    "\n",
    "    def single_forward(self, x):\n",
    "\n",
    "        x = x.swapaxes(1,0)\n",
    "\n",
    "        ##### Initialize hidden states at t=0 #####\n",
    "        ### Encoding layer with populations\n",
    "        mem_pops_enc = torch.empty((input_channels,x.shape[1],output_pop), dtype=torch.float, device=device)\n",
    "        spk_pops_enc = torch.empty((input_channels,x.shape[1],output_pop), dtype=torch.float, device=device)\n",
    "        cur_pops_enc = torch.empty((input_channels,x.shape[1],output_pop), dtype=torch.float, device=device)\n",
    "        ### Recurrent layer\n",
    "        spk1, syn1, mem1 = self.lif1.init_rsynaptic()\n",
    "        ### Output layer\n",
    "        syn2, mem2 = self.lif2.init_synaptic()\n",
    "\n",
    "        # Record the final layer\n",
    "        spk2_rec = []\n",
    "        syn2_rec = []\n",
    "        mem2_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            ### Encoding layer with populations\n",
    "            for num,el in enumerate(self.enc_pops):\n",
    "                cur_pops_enc[num] = el(torch.tile(x[step,:,num],(self.pop_size,1)).swapaxes(1,0))\n",
    "            for num,el in enumerate(self.lif_enc_pops):\n",
    "                spk_pops_enc[num], mem_pops_enc[num] = el(cur_pops_enc[num], mem_pops_enc[num])\n",
    "            spk_enc = spk_pops_enc.clone().permute(1, 0, 2).reshape((x.shape[1],input_channels*output_pop)).requires_grad_(True)\n",
    "            ### Recurrent layer\n",
    "            cur1 = self.fc1(spk_enc)\n",
    "            spk1, syn1, mem1 = self.lif1(cur1, spk1, syn1, mem1)\n",
    "            ### Output layer\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, syn2, mem2 = self.lif2(cur2, syn2, mem2)\n",
    "\n",
    "            spk2_rec.append(spk2)\n",
    "            syn2_rec.append(syn2)\n",
    "            mem2_rec.append(mem2)\n",
    "\n",
    "        return torch.stack(spk2_rec, dim=0), torch.stack(syn2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        ### Encoding layer with populations\n",
    "        for num,el in enumerate(self.enc_pops):\n",
    "            self.cur_pops_enc[num] = el(torch.tile(x[:,num],(self.pop_size,1)).swapaxes(1,0))\n",
    "        for num,el in enumerate(self.lif_enc_pops):\n",
    "            self.spk_pops_enc[num], self.mem_pops_enc[num] = el(self.cur_pops_enc[num], self.mem_pops_enc[num])\n",
    "        spk_enc = self.spk_pops_enc.clone().permute(1, 0, 2).reshape((x.shape[0],input_channels*output_pop)).requires_grad_(True)\n",
    "        ### Recurrent layer\n",
    "        cur1 = self.fc1(spk_enc)\n",
    "        self.spk1, self.syn1, self.mem1 = self.lif1(cur1, self.spk1, self.syn1, self.mem1)\n",
    "        ### Output layer\n",
    "        cur2 = self.fc2(self.spk1)\n",
    "        spk2, self.syn2, self.mem2 = self.lif2(cur2, self.syn2, self.mem2)\n",
    "\n",
    "        return spk2, self.mem2\n",
    "\n",
    "    # def reset(self, x):\n",
    "    #     ### Encoding layer with populations\n",
    "    #     self.mem_pops_enc = torch.empty((input_channels,x.shape[1],output_pop), dtype=torch.float, device=device)\n",
    "    #     self.spk_pops_enc = torch.empty((input_channels,x.shape[1],output_pop), dtype=torch.float, device=device)\n",
    "    #     self.cur_pops_enc = torch.empty((input_channels,x.shape[1],output_pop), dtype=torch.float, device=device)\n",
    "    #     ### Hidden layer\n",
    "    #     self.spk1, self.syn1, self.mem1 = self.lif1.init_rsynaptic()\n",
    "    #     ### Output layer\n",
    "    #     self.syn2, self.mem2 = self.lif2.init_synaptic()\n",
    "\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZRmatYoyim_"
   },
   "outputs": [],
   "source": [
    "### Set the loss function\n",
    "loss_fn = SF.ce_count_loss()\n",
    "\n",
    "### Set the optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=settings['lr'], betas=(0.9, 0.999))\n",
    "\n",
    "### Set the batch size\n",
    "batch_size = int(settings[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoHU8jk6yim_"
   },
   "source": [
    "#### Training (with validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFlGUW8lyim_"
   },
   "outputs": [],
   "source": [
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6CPak3eYyim_"
   },
   "outputs": [],
   "source": [
    "training_results = []\n",
    "validation_results = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "  train_loss, train_acc = training_loop(ds_train, batch_size, net, optimizer, loss_fn, device)\n",
    "  val_loss, val_acc = val_test_loop(ds_val, batch_size, net, loss_fn, device)\n",
    "\n",
    "  training_results.append([train_loss, train_acc])\n",
    "  validation_results.append([val_loss, val_acc])\n",
    "\n",
    "  print(\"Epoch {}/{}: \\n\\ttraining loss: {} \\n\\tvalidation loss: {} \\n\\ttraining accuracy: {}% \\n\\tvalidation accuracy: {}%\".format(epoch+1, num_epochs, training_results[-1][0], validation_results[-1][0], np.round(training_results[-1][1]*100,4), np.round(validation_results[-1][1]*100,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kyPXZr9Iyim_"
   },
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLM1Z1D5yim_"
   },
   "outputs": [],
   "source": [
    "test_results, lbl_probs, spk_out = val_test_loop(ds_test, batch_size, net, loss_fn, device, label_probabilities=True, return_spikes=True)\n",
    "\n",
    "print(\"\\nTest accuracy: {}%\".format(np.round(test_results[1]*100,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jg5WDd-SyinA"
   },
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "297fGl3wyinA"
   },
   "outputs": [],
   "source": [
    "create_directory('model_data')\n",
    "torch.save(net.state_dict(), './model_data/HAR_RSNN.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vycr8fIuyinA"
   },
   "source": [
    "#### Neurobench Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhGy_1fTyinA"
   },
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "net.load_state_dict(torch.load('./model_data/HAR_RSNN.pth'))\n",
    "\n",
    "model = SNNTorchModel(net)\n",
    "test_set_loader = DataLoader(ds_test, batch_size=int(settings[\"batch_size\"]), shuffle=True, drop_last=False)\n",
    "postprocessors = [choose_max_count]\n",
    "\n",
    "static_metrics = [\"model_size\"]\n",
    "workload_metrics = [\"classification_accuracy\"]\n",
    "\n",
    "benchmark = Benchmark(model, test_set_loader, [], postprocessors, [static_metrics, workload_metrics])\n",
    "results = benchmark.run()\n",
    "\n",
    "results = [results[key] for key in results.keys()]\n",
    "results.insert(0, 'RSNN')\n",
    "\n",
    "network_results.append(copy.copy(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9ogqWpNyinA"
   },
   "source": [
    "#### Single-sample inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QMQBVbG-yinA"
   },
   "outputs": [],
   "source": [
    "single_sample = next(iter(DataLoader(ds_test, batch_size=1, shuffle=True)))\n",
    "print(\"Randomly selected sample: {}\".format(labels_activity[single_sample[1].cpu()[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6qx9y7ZyinA"
   },
   "outputs": [],
   "source": [
    "### Inference\n",
    "_, lbl_probs, spk_out = val_test_loop(TensorDataset(single_sample[0],single_sample[1]), 1, net, loss_fn, device, label_probabilities=True, return_spikes=True)\n",
    "\n",
    "### Plot output spiking activity\n",
    "spk_out = np.moveaxis(spk_out,1,2)\n",
    "spk_out = np.squeeze(spk_out, axis=-1)\n",
    "spk_out.shape\n",
    "aer = []\n",
    "for num,el in enumerate(spk_out):\n",
    "  addr = np.where(el)[0].tolist()\n",
    "  if len(addr) > 0:\n",
    "    for ii in addr:\n",
    "      aer.append([num,ii])\n",
    "aer = np.array(aer)\n",
    "plt.scatter(aer[:,0], aer[:,1], s=1)\n",
    "plt.xlabel(\"Time step (a.u.)\")\n",
    "plt.ylabel(\"Neuron\")\n",
    "plt.title(\"Spiking output activity (activity: {}, prediction: {})\".format(labels_activity[single_sample[1].cpu()[0]],labels_activity[np.argmax(lbl_probs.cpu())]))\n",
    "plt.ylim(-0.5,6.5)\n",
    "plt.xlim((-0.5,num_steps+0.5))\n",
    "plt.yticks(range(7),labels_activity)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nLabels probabilities:\")\n",
    "for num,el in enumerate(labels_activity):\n",
    "  print(\"\\t{} \\n\\t\\t{}%\".format(el,np.round(lbl_probs.cpu().numpy()[0][num]*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlYI1jKB01PY"
   },
   "source": [
    "## Convolutional SNN\n",
    "\n",
    "Training, Validation and Test of a CSNN\n",
    "\n",
    "Neurobench Metrics extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "erDlQe8HRlr-"
   },
   "outputs": [],
   "source": [
    "settings = {\n",
    "    'conv_1_out_fts': 200,\n",
    "    'conv_1_kernel_size': 2,\n",
    "    'maxpool_1_fts': 2,\n",
    "    'conv_1_pad': 4,\n",
    "    'leaky_1_beta': 0.4,\n",
    "    'leaky_1_thr': 0.002,\n",
    "    'conv_2_in_fts': 100,\n",
    "    'conv_2_out_fts': 256,\n",
    "    'conv_2_kernel_size': 1,\n",
    "    'maxpool_2_fts': 2,\n",
    "    'leaky_2_beta': 0.3,\n",
    "    'leaky_2_thr': 0.001,\n",
    "    'leaky_3_beta': 0.5,\n",
    "    'leaky_3_thr': 0.001,\n",
    "    'lr': 1.e-3,\n",
    "    'batch_size': 256,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0z4AsVtN4Yo7"
   },
   "outputs": [],
   "source": [
    "input_enc = 6\n",
    "num_outputs = 7\n",
    "num_steps = 40\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(input_enc, settings['conv_1_out_fts'], kernel_size=settings['conv_1_kernel_size'], padding=settings['conv_1_pad'])\n",
    "        self.max1 = nn.MaxPool2d(settings['maxpool_1_fts'])\n",
    "        self.leaky1 = snn.Leaky(beta=settings['leaky_1_beta'], init_hidden=True, threshold=settings['leaky_1_thr'])\n",
    "        self.conv2 = nn.Conv1d(settings['conv_2_in_fts'], settings['conv_2_out_fts'], kernel_size=settings['conv_2_kernel_size'])\n",
    "        self.max2 = nn.MaxPool2d(settings['maxpool_2_fts'])\n",
    "        self.leaky2 = snn.Leaky(beta=settings['leaky_2_beta'], init_hidden=True, threshold=settings['leaky_2_thr'])\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(settings['conv_2_out_fts'], num_outputs)\n",
    "        self.leaky3 = snn.Leaky(beta=settings['leaky_3_beta'], output=True, init_hidden=True, threshold=settings['leaky_3_thr'])\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = self.conv1(input.reshape(input.shape[0], input.shape[1], 1))\n",
    "        x = self.max1(x)\n",
    "        x = self.leaky1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max2(x)\n",
    "        x = self.leaky2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "        spk_out, mem_out = self.leaky3(x)\n",
    "        return spk_out, mem_out\n",
    "\n",
    "    def single_forward(self, input):\n",
    "        mem_rec = []\n",
    "        spk_rec = []\n",
    "\n",
    "        self.leaky1.init_leaky()\n",
    "        self.leaky2.init_leaky()\n",
    "        self.leaky3.init_leaky()\n",
    "        utils.reset(self)\n",
    "        for step in range(num_steps):\n",
    "\n",
    "            new_input = input[:, step, :]\n",
    "            x = self.conv1(new_input.reshape(new_input.shape[0], new_input.shape[1], 1))\n",
    "            x = self.max1(x)\n",
    "            x = self.leaky1(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.max2(x)\n",
    "            x = self.leaky2(x)\n",
    "            x = self.flatten(x)\n",
    "            x = self.linear(x)\n",
    "            spk_out, mem_out = self.leaky3(x)\n",
    "\n",
    "            spk_rec.append(spk_out)\n",
    "            mem_rec.append(mem_out)\n",
    "\n",
    "        return torch.stack(spk_rec), torch.stack(mem_rec)\n",
    "\n",
    "    def reset(self):\n",
    "      self.leaky1.init_leaky()\n",
    "      self.leaky2.init_leaky()\n",
    "      self.leaky3.init_leaky()\n",
    "\n",
    "    def frequency(self):\n",
    "      acquisition_rate = 20\n",
    "      temporal_window = num_steps/acquisition_rate\n",
    "      return 1/temporal_window\n",
    "\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8uksy-_-5zKc"
   },
   "outputs": [],
   "source": [
    "### Set the loss function\n",
    "loss_fn = SF.ce_count_loss()\n",
    "\n",
    "### Set the optimizer\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=settings['lr'], betas=(0.9, 0.999))\n",
    "\n",
    "### Set the batch size\n",
    "batch_size = settings[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzyok0ia567Y"
   },
   "source": [
    "#### Training (with validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tE9Q9FEh6EyC"
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "training_results = []\n",
    "validation_results = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "  train_loss, train_acc = training_loop(ds_train, batch_size, net, optimizer, loss_fn, device)\n",
    "  val_loss, val_acc = val_test_loop(ds_val, batch_size, net, loss_fn, device)\n",
    "\n",
    "  training_results.append([train_loss, train_acc])\n",
    "  validation_results.append([val_loss, val_acc])\n",
    "\n",
    "  print(\"Epoch {}/{}: \\n\\ttraining loss: {} \\n\\tvalidation loss: {} \\n\\ttraining accuracy: {}% \\n\\tvalidation accuracy: {}%\".format(epoch+1, num_epochs, training_results[-1][0], validation_results[-1][0], np.round(training_results[-1][1]*100,4), np.round(validation_results[-1][1]*100,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mp5OlDs6Nn7"
   },
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sa__FLVs6NoX"
   },
   "outputs": [],
   "source": [
    "test_results, lbl_probs, spk_out = val_test_loop(ds_test, batch_size, net, loss_fn, device, label_probabilities=True, return_spikes=True)\n",
    "\n",
    "print(\"\\nTest accuracy: {}%\".format(np.round(test_results[1]*100,4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQDFquzA6Wdp"
   },
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ja0VpKMh6Wdq"
   },
   "outputs": [],
   "source": [
    "create_directory('model_data')\n",
    "torch.save(net.state_dict(), './model_data/HAR_SCNN.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AndMz7gO6ea3"
   },
   "source": [
    "#### Neurobench Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tyu3eJoz6ea4"
   },
   "outputs": [],
   "source": [
    "net = Net().to(device)\n",
    "net.load_state_dict(torch.load('./model_data/HAR_SCNN.pth'))\n",
    "\n",
    "model = SNNTorchModel(net)\n",
    "test_set_loader = DataLoader(ds_test, batch_size=settings[\"batch_size\"], shuffle=True, drop_last=False)\n",
    "postprocessors = [choose_max_count]\n",
    "\n",
    "static_metrics = [\"model_size\"]\n",
    "workload_metrics = [\"classification_accuracy\"]\n",
    "\n",
    "benchmark = Benchmark(model, test_set_loader, [], postprocessors, [static_metrics, workload_metrics])\n",
    "results = benchmark.run()\n",
    "\n",
    "results = [results[key] for key in results.keys()]\n",
    "results.insert(0, 'SCNN')\n",
    "\n",
    "network_results.append(copy.copy(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiYB2dKrBol2"
   },
   "source": [
    "## Networks Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y51YN_a9ASgx"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(network_results, columns=[\"Model Name\", \"Model Size\", \"Classification Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "vJsVu0H2FIol",
    "CuyCkI5mB1Qc",
    "cc4eYiEoCchd",
    "V0pq1QdFDEH9",
    "qQga4Aa7HaM1",
    "ZISpcrO3JUGv",
    "2ztuHhcAwzz0",
    "33yYb13Lyim_",
    "GlYI1jKB01PY"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e5f42e4452efdb55deabd82d647dd2921cc3aaae1fb4d0764999ca11e054984"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
