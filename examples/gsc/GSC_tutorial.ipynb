{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGm4fad3M-Sr"
   },
   "source": [
    "# Google Speech Commands Benchmark Tutorial\n",
    "\n",
    "This tutorial aims to provide an insight on how the NeuroBench framework is organized and how you can use it to benchmark your own models!\n",
    "\n",
    "## About Google Speech Commands (GSC):\n",
    "Google Speech Commands is a keyword spotting dataset. Voice commands represent a natural and easily accessible modality for human-machine interaction. Keyword detection, in particular, is frequently employed in edge devices that operate in always-listening, wake-up situations, where it triggers more computationally demanding processes such as automatic speech recognition. Keyword spotting finds application in activating voice assistants, speech data mining, audio indexing, and phone call routing. Given that it generally operates in always-on and battery-powered edge scenarios, keyword detection represents a pertinent benchmark for energy-efficient neuromorphic solutions.\n",
    "### Dataset:\n",
    "The GSC dataset (V2) is a commonly used dataset in assessing the performance of keyword spotting algorithms. The dataset consists of 105,829 1 second utterances of 35 different words from 2,618 distinct speakers. The data is encoded as linear 16-bit, single-channel, pulse code modulated values, at a 16 kHz sampling frequency.\n",
    "\n",
    "### Benchmark Task:\n",
    "The task is to classify keywords from the GSC dataset test split, after training using the train and val splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will import the relevant libraries. These include the dataset, pre- and post-processors, model wrapper, and benchmark object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqtM6XbMM_hO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# import the dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# import the dataset, preprocessors and postprocessors you want to use\n",
    "from neurobench.datasets import SpeechCommands\n",
    "from neurobench.metrics.static import Footprint\n",
    "from neurobench.processors.preprocessors import S2SPreProcessor\n",
    "from neurobench.processors.postprocessors import ChooseMaxCount\n",
    "\n",
    "# import the NeuroBench wrapper to wrap the snnTorch model for usage in the NeuroBench framework\n",
    "from neurobench.models import SNNTorchModel\n",
    "# import the benchmark class\n",
    "from neurobench.benchmarks import Benchmark\n",
    "\n",
    "from neurobench.metrics.workload import (\n",
    "    ActivationSparsity,\n",
    "    SynapticOperations,\n",
    "    ClassificationAccuracy\n",
    ")\n",
    "from neurobench.metrics.static import (\n",
    "    Footprint,\n",
    "    ConnectionSparsity,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7HMjVPX7LZh"
   },
   "source": [
    "For this tutorial, we will make use of a simple feedforward SNN, written using snnTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0yYDNRZ7UxY"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "\n",
    "beta = 0.9\n",
    "spike_grad = surrogate.fast_sigmoid()\n",
    "net = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(20, 256),\n",
    "    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "    nn.Linear(256, 256),\n",
    "    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "    nn.Linear(256, 256),\n",
    "    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "    nn.Linear(256, 35),\n",
    "    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNIgTfvuOMe-"
   },
   "source": [
    "To get started, we will load our desired dataset in a dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chZeyUTAOQ6B"
   },
   "outputs": [],
   "source": [
    "# data in repo root dir\n",
    "test_set = SpeechCommands(path=\"../../data/speech_commands/\", subset=\"testing\")\n",
    "\n",
    "test_set_loader = DataLoader(test_set, batch_size=500, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTB808RoNXqL"
   },
   "source": [
    "Here, we are loading a pre-trained model. The model is wrapped in the SNNTorchModel wrapper, which includes boilerplate inference code and interfaces with the top-level Benchmark class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4jOfnt6OeIH"
   },
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load(\"model_data/s2s_gsc_snntorch\", map_location=torch.device('cpu')))\n",
    "\n",
    "# Wrap our net in the SNNTorchModel wrapper\n",
    "model = SNNTorchModel(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfRfdvXvOqRP"
   },
   "source": [
    "Specify any pre-processors and post-processors you want to use. These will be applied to your data before feeding into the model, and to the output spikes respectively.\n",
    "Here, we are using the Speech2Spikes pre-processor to convert the keyword audio data to spikes, and the choose_max_count post-processor which returns a classification based on the neuron with the greatest number of spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GHY8vTROwzP"
   },
   "outputs": [],
   "source": [
    "preprocessors = [S2SPreProcessor()]\n",
    "postprocessors = [ChooseMaxCount()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9doNsI0O0Jl"
   },
   "source": [
    "Next specify the metrics which you want to calculate. The metrics include static metrics, which are computed before any model inference, and workload metrics, which show inference results.\n",
    "\n",
    "- Footprint: Bytes used to store the model parameters and buffers.\n",
    "- Connection sparsity: Proportion of zero weights in the model.\n",
    "- Classification accuracy: Accuracy of keyword predictions.\n",
    "- Activation sparsity: Proportion of zero activations, averaged over all neurons, timesteps, and samples.\n",
    "- Synaptic operations: Number of weight-activation operations, averaged over keyword samples.\n",
    "  - Effective MACs: Number of non-zero multiply-accumulate synops, where the activations are not spikes with values -1 or 1.\n",
    "  - Effective ACs: Number of non-zero accumulate synops, where the activations are -1 or 1 only.\n",
    "  - Dense: Total zero and non-zero synops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDUczVTkPOsQ"
   },
   "outputs": [],
   "source": [
    "static_metrics = [Footprint, ConnectionSparsity]\n",
    "workload_metrics = [ClassificationAccuracy, ActivationSparsity, SynapticOperations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KXQYfiJpPTZb"
   },
   "source": [
    "Next, we instantiate the benchmark. We pass the model, the dataloader, the preprocessors, the postprocessor and the list of the static and data metrics which we want to measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0_N96ADPeO5"
   },
   "outputs": [],
   "source": [
    "benchmark = Benchmark(model, test_set_loader, preprocessors, postprocessors, [static_metrics, workload_metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ytLJ-dUPp0b"
   },
   "source": [
    "Now, let's run the benchmark and print our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ldww7kiYPsU2"
   },
   "outputs": [],
   "source": [
    "results = benchmark.run()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "{'footprint': 583900, 'connection_sparsity': 0.0,\n",
    "'classification_accuracy': 0.8484325295196562, 'activation_sparsity': 0.9675956131759854, \n",
    "'synaptic_operations': {'Effective_MACs': 0.0, 'Effective_ACs': 3556689.9895502045, 'Dense': 29336955.0}}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
