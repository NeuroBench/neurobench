{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Custom Metrics in NeuroBench: A Deep Dive\n",
    "\n",
    "This workshop guide explains how to create custom metrics in the NeuroBench framework, using the AverageActivity metric as a practical example. We'll explore how to implement metrics that can analyze neural network behavior, particularly focusing on spiking neural networks.\n",
    "\n",
    "## Understanding Metric Types in NeuroBench\n",
    "\n",
    "NeuroBench supports three types of metrics:\n",
    "\n",
    "1. **Static Metrics**: Evaluate fixed properties of the model (e.g., parameter count)\n",
    "2. **Workload Metrics**: Evaluate performance during inference\n",
    "3. **Accumulated Metrics**: A special type of workload metric that accumulates statistics across batches\n",
    "\n",
    "In this workshop, we'll focus on creating an AccumulatedMetric, which is particularly useful for analyzing spike related informationas it allows us to gather statistics across multiple batches of data and compute desired metrics at the end.\n",
    "\n",
    "## The AverageActivity Metric: A Case Study\n",
    "\n",
    "Let's examine how to create a metric that analyzes the activity patterns of neurons across different layers in a spiking neural network.\n",
    "\n",
    "We are interested in the average activity of neurons across different layers. We want to compute the min, max, mean, median, and q1 and q3 of the activity of neurons across different layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting Up the Metric Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import all our desired libraries, and the metric base class. We are creating an AccumulatedMetric, so we need to import the base class from neurobench.metrics.abstract.workload_metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from neurobench.metrics.abstract.workload_metric import AccumulatedMetric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the class for our metric, inheriting from the AccumulatedMetric base class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key points:\n",
    "- Inherit from `AccumulatedMetric` for batch-wise accumulation\n",
    "- Set `requires_hooks=True` to access activation information\n",
    "- Initialize dictionaries to store statistics across batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding Hooks\n",
    "\n",
    "Hooks are essential for accessing spike information after running a model. They allow us to intercept and record activation values during the forward pass. Both layer and neuron hooks are supported. We can access the data being passed in each layer or activation and the output values of each layer or activation.\n",
    "\n",
    "When we set `requires_hooks=True`, hooks are automatically added to the model. We can access them through the `activation_hooks` (as we are interested in activations) attribute of the model. Optionally, we can also manually add hooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageActivityMetric(AccumulatedMetric):\n",
    "    \"\"\"\n",
    "    A workload metric that computes activity statistics for each layer in a neural network.\n",
    "    For each layer, it tracks the min, max, mean, median, and q1 and q3 of the activity of its neurons.\n",
    "    \n",
    "    This metric is particularly useful for analyzing:\n",
    "    1. Layer-wise activation patterns\n",
    "    2. Neuron activity distribution\n",
    "    3. Potential dead neurons or saturation\n",
    "    4. Layer-specific sparsity patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(requires_hooks=True)\n",
    "        self.layer_activities = defaultdict(list)  # Store activities for each layer\n",
    "        self.num_batches = 0\n",
    "        self.all_spikes = {}\n",
    "        self.min_activities = {}\n",
    "        self.max_activities = {}\n",
    "        self.mean_activities = {}\n",
    "        self.q1_activities = {}\n",
    "        self.q3_activities = {}\n",
    "  \n",
    "    def _get_layer_activities(self, model) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Extract activities from all layers in the model.\n",
    "        This method should be customized based on the model architecture.\n",
    "        \n",
    "        Args:\n",
    "            model: The neural network model\n",
    "            \n",
    "        Returns:\n",
    "            activity of each neuron in each layer as a dictionary\n",
    "        \"\"\"\n",
    "        spike_lsts = {}\n",
    "        for i, hook in enumerate(model.activation_hooks):\n",
    "            if not hook.activation_outputs:\n",
    "                continue\n",
    "\n",
    "            spike_lsts[f'activation_layer_{i+1}'] = hook.activation_outputs\n",
    "\n",
    "        activities = {}\n",
    "        for layer_name, spikes in spike_lsts.items():\n",
    "            if layer_name not in self.all_spikes:\n",
    "                self.all_spikes[layer_name] = [torch.stack(spikes, dim=0)]\n",
    "            else:\n",
    "                self.all_spikes[layer_name].append(torch.stack(spikes, dim=0))\n",
    "            # activities[layer_name] = torch.stack(spikes, dim=0).sum(dim=0)/len(spikes) # sum over entire sequence and divide by sequence length\n",
    "        return activities, len(spikes)\n",
    "    \n",
    "    def __call__(self, model, preds, data):\n",
    "        \"\"\"\n",
    "        Accumulate activity statistics for each layer.\n",
    "        We return the result\n",
    "        \n",
    "        Args:\n",
    "            model: The neural network model\n",
    "            preds: Model predictions (not used in this metric)\n",
    "            data: Input data (not used in this metric)\n",
    "\n",
    "        \"\"\"\n",
    "        # Get activities for all layers\n",
    "        self._get_layer_activities(model)\n",
    "        \n",
    "        self.num_batches += 1\n",
    "\n",
    "        return self.compute()\n",
    "    \n",
    "    def compute(self) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "        \"\"\"\n",
    "        Compute the final activity statistics for each layer.\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary containing statistics for each layer:\n",
    "            {\n",
    "                'layer_name': {\n",
    "                    'mean': mean activity per neuron,\n",
    "                    'std': standard deviation of activities,\n",
    "                    'histogram': histogram of activities\n",
    "                }\n",
    "            }\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for layer_name, spikes in self.all_spikes.items():\n",
    "            # cat all batches\n",
    "            spikes = torch.cat(spikes, dim=1)\n",
    "            spike_percentages = ((spikes.sum(dim=0)/spikes.shape[0]).sum(dim=0)/spikes.shape[1]).cpu().detach().numpy() # first sum over batch, then over sequence length\n",
    "            results[layer_name] = {\n",
    "                'min': spike_percentages.min(),\n",
    "                'max': spike_percentages.max(),\n",
    "                'mean': spike_percentages.mean(),\n",
    "                'std': spike_percentages.std(),\n",
    "                'median': np.median(spike_percentages),\n",
    "                'q1': np.percentile(spike_percentages, 25),\n",
    "                'q3': np.percentile(spike_percentages, 75),\n",
    "                'histogram': spike_percentages\n",
    "            }\n",
    "        return results\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the accumulated statistics.\"\"\"\n",
    "        self.layer_activities.clear()\n",
    "        self.num_batches = 0\n",
    "        # self.all_spikes = {}\n",
    "    \n",
    "    @classmethod\n",
    "    def plot_activity_distributions(cls, results: Dict[str, Dict[str, np.ndarray]]):\n",
    "        \"\"\"\n",
    "        Plot boxplots of activity distributions for each layer side by side on one figure.\n",
    "        \n",
    "        Args:\n",
    "            results: Results from compute() method\n",
    "        \"\"\"\n",
    "        # Create a single figure\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        results = results['AverageActivityMetric']\n",
    "        # Prepare data for plotting\n",
    "        layer_names = list(results.keys())\n",
    "        activity_data = [results[layer]['histogram'] for layer in layer_names]\n",
    "        \n",
    "        # Create boxplot\n",
    "        bp = plt.boxplot(activity_data, \n",
    "                        labels=layer_names,\n",
    "                        vert=True,\n",
    "                        widths=0.5,\n",
    "                        showmeans=True,\n",
    "                        meanline=True,\n",
    "                        patch_artist=True)\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title('Average Activity of Neurons per Layer')\n",
    "        plt.xlabel('Layer')\n",
    "        plt.ylabel('Activity')\n",
    "        plt.ylim(0, 0.5)\n",
    "        \n",
    "        # Rotate x-axis labels for better readability\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        \n",
    "        # Add grid for better readability\n",
    "        plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Adjust layout to prevent label cutoff\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Support\n",
    "\n",
    "We have included a class method which creates boxplots of the activity distributions for each layer side by side on one figure. We demonstrate that all data required after running the benchmark, should be returned in the results dictionary of the __call__ method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using the Metric in a Benchmark\n",
    "\n",
    "We build on the GSC example to show how to use the metric in a benchmark.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\n\u001b[32m     27\u001b[39m device = torch.device(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m file_path = pathlib.Path(\u001b[34;43m__file__\u001b[39;49m).parent.parent\n\u001b[32m     30\u001b[39m model_path = os.path.join(file_path, \u001b[33m\"\u001b[39m\u001b[33mgsc/model_data/s2s_gsc_snntorch\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     31\u001b[39m data_dir = os.path.join(file_path, \u001b[33m\"\u001b[39m\u001b[33m../../data/speech_commands\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# data in repo root dir\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from neurobench.datasets import SpeechCommands\n",
    "from neurobench.processors.preprocessors import S2SPreProcessor\n",
    "from neurobench.processors.postprocessors import ChooseMaxCount\n",
    "\n",
    "from neurobench.models import SNNTorchModel\n",
    "from neurobench.benchmarks import Benchmark\n",
    "\n",
    "from neurobench.metrics.workload import (\n",
    "    ActivationSparsity,\n",
    "    SynapticOperations,\n",
    "    ClassificationAccuracy\n",
    ")\n",
    "from neurobench.metrics.static import (\n",
    "    Footprint,\n",
    "    ConnectionSparsity,\n",
    ")\n",
    "from average_activity_metric import AverageActivityMetric\n",
    "\n",
    "from examples.gsc.SNN import net\n",
    "from pprint import pprint\n",
    "import pathlib\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "file_path = pathlib.Path(__file__).parent.parent\n",
    "model_path = os.path.join(file_path, \"gsc/model_data/s2s_gsc_snntorch\")\n",
    "data_dir = os.path.join(file_path, \"../../data/speech_commands\") # data in repo root dir\n",
    "\n",
    "test_set = SpeechCommands(path=data_dir, subset=\"testing\")\n",
    "\n",
    "test_set_loader = DataLoader(test_set, batch_size=500, shuffle=True)\n",
    "\n",
    "net.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "\n",
    "## Define model ##\n",
    "model = SNNTorchModel(net)\n",
    "\n",
    "preprocessors = [S2SPreProcessor(device=device)]\n",
    "postprocessors = [ChooseMaxCount()]\n",
    "\n",
    "static_metrics = [Footprint, ConnectionSparsity]\n",
    "workload_metrics = [AverageActivityMetric]\n",
    "\n",
    "benchmark = Benchmark(model, test_set_loader, preprocessors, postprocessors, [static_metrics, workload_metrics])\n",
    "results = benchmark.run(device=device)\n",
    "pprint(results)\n",
    "\n",
    "# plot activity distributions\n",
    "AverageActivityMetric.plot_activity_distributions(results)\n",
    "\n",
    "# Results:\n",
    "# {'Footprint': 583900, 'ConnectionSparsity': 0.0, \n",
    "# 'ClassificationAccuracy': 0.85633802969095, 'ActivationSparsity': 0.9668664144456199, \n",
    "# 'SynapticOperations': {'Effective_MACs': 0.0, 'Effective_ACs': 3289834.3206724217, 'Dense': 29030400.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Accumulated Metrics**:\n",
    "   - Perfect for analyzing spiking neural networks\n",
    "   - Allow gathering statistics across multiple batches\n",
    "   - Require hooks for accessing activation information\n",
    "\n",
    "2. **Hook System**:\n",
    "   - Provides access to spike information\n",
    "   - Enables analysis of temporal dynamics\n",
    "   - Works with various spiking neural network architectures\n",
    "\n",
    "3. **Metric Structure**:\n",
    "   - `__init__`: Set up hooks and storage\n",
    "   - `__call__`: Process each batch\n",
    "   - `compute`: Calculate final statistics\n",
    "   - `reset`: Clear accumulated data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurobench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
