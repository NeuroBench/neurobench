{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGm4fad3M-Sr"
   },
   "source": [
    "# Non-Human Primate (NHP) Motor Prediction Benchmark Tutorial\n",
    "\n",
    "This tutorial aims to provide an insight on how the NeuroBench framework is organized and how you can use it to benchmark your own models!\n",
    "\n",
    "## About NHP Motor Prediction:\n",
    "Studying models which can accurately replicate features of biological computation presents opportunities in understanding sensorimotor behavior and developing closed-loop methods for future robotic agents. It also is foundational to the development of wearable or implantable neuro-prosthetic devices that can accurately generate motor activity from neural or muscle signals.\n",
    "\n",
    "### Dataset:\n",
    "The dataset that we utilize in this study consists of multi-channel recordings obtained from the sensorimotor cortex of two non-human primates (NHP) during self-paced reaching movements towards a grid of targets. A link to the dataset can be found [here](https://zenodo.org/records/583331). The variable $x$ is represented by threshold crossing times (or spike times) and sorted units for each of the recording channels. The target $y$ is represented by 2-dimensional position coordinates of the fingertip of the reaching hand, sampled at a frequency of 250 Hz. The complete dataset contains 37 sessions spanning 10 months for NHP-1 and 10 sessions from NHP-2 spanning one month. For this study, three sessions from each NHP were\n",
    "selected to include the entire recording duration, resulting in a total of 8712 seconds of data.\n",
    "\n",
    "### Benchmark Task:\n",
    "In the context of predictive modeling, time series prediction is a task which entails the forecasting of one or more observations of a target variable, y, at some point between the current time, $t$, and a future time, $t$ + $t_f$ , by utilizing a sequence of another variable, $x$, from the past, {$x(t âˆ’ th), . . . , x(t)$}. In the primate reaching task, the goal is to predict the $X$ and $Y$ components of finger velocity, $y$, from past neural data, $x$. The model may be trained separately for each session to account for inter-day neural variability. The data is split such that the first 75% of reaches are available for training and validation, while the latter 25% of reaches are used for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will import the relevant libraries. These include the datasets, model wrapper, and benchmark object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from neurobench.datasets import PrimateReaching\n",
    "from neurobench.models.torch_model import TorchModel\n",
    "from neurobench.benchmarks import Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we demonstrate small ANN and SNN architectures. First, the ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from examples.primate_reaching.ANN import ANNModel2D"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we will only use one session from NHP Indy, `indy_20160622_01`. Note that there are 6 sessions in total, covering NHP Indy and NHP Loco. The dataset preprocesses the events into 4 ms bins, denoted by `bin_width`, such that the number of spikes for each of 96 cortical sensors during that time bin are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"indy_20160622_01\"\n",
    "\n",
    "# The dataloader and preprocessor has been combined together into a single class\n",
    "data_dir = \"../../../data/primate_reaching/PrimateReachingDataset/\" # data in repo root dir\n",
    "dataset = PrimateReaching(file_path=data_dir, filename=filename,\n",
    "                        num_steps=1, train_ratio=0.5, bin_width=0.004,\n",
    "                        biological_delay=0, remove_segments_inactive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is treated such that each time series element is considered a separate sample. The sample is passed to the model, which predicts an X and Y velocity based on it and historical data. The data is shaped as `[num_samples, 1, 96]` for NHP Indy files (96 cortical sensors), and `[num_samples, 1, 192]` for NHP Loco files (192 cortical sensors), in order to fit with the three dimensional data format of NeuroBench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_sample, single_label = dataset[0]\n",
    "single_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, wrap the dataset in a DataLoader. Importantly, the data should not be shuffled if the model expects that the data appears in temporal order. Since the ANN model uses a memory buffer to store recent data, shuffle must be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_loader = DataLoader(Subset(dataset, dataset.ind_test), batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instatiate then load the model. This is a pretrained feedforward linear model with two hidden layers, which uses a bin_window of 200 ms. Thus, it saves 50 timesteps in a memory buffer, since each timestep represents 4 ms. The spikes from the 50 most recent timesteps are summed to generate the input to the first layer of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ANNModel2D(input_dim=dataset.input_feature_size, layer1=32, layer2=48, \n",
    "                     output_dim=2, bin_window=0.2, drop_rate=0.5)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.load_state_dict(torch.load(\"./model_data/2D_ANN_Weight/\"+filename+\"_model_state_dict.pth\", map_location=device))\n",
    "\n",
    "model = TorchModel(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No pre- or post-processors are used for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessors = []\n",
    "postprocessors = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the metrics. Correctness for this task is $R^2$, which is computed separately for the X and Y dimensions and averaged together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_metrics = [\"footprint\", \"connection_sparsity\"]\n",
    "workload_metrics = [\"r2\", \"activation_sparsity\", \"synaptic_operations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to run the benchmark!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark expects the following:\n",
    "benchmark = Benchmark(model, test_set_loader, [], [], [static_metrics, workload_metrics])\n",
    "results = benchmark.run()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected results for ANN:\n",
    "{'footprint': 20824, 'connection_sparsity': 0.0, 'activation_sparsity': 0.7068512007122443, 'r2': 0.6327020525932312, 'synaptic_operations': {'Effective_MACs': 4306.322415210456, 'Effective_ACs': 0.0, 'Dense': 4702.261627687736}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will demonstrate the SNN benchmark. Import the model and related SNN units, and reinitialize the dataloader. Here, since the model is sequential, we are loading the entire dataset as a single batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.primate_reaching.SNN2 import SNN2\n",
    "import snntorch as snn\n",
    "test_set_loader = DataLoader(Subset(dataset, dataset.ind_test), batch_size=len(dataset.ind_test), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and load the network. The SNN2 model architecture is a very simple two-layer linear feedforward SNN, which is implemented using SNNTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SNN2(input_size=dataset.input_feature_size)\n",
    "net.load_state_dict(torch.load(\"./model_data/SNN2_{}.pt\".format(filename), map_location=torch.device('cpu'))\n",
    "                    ['model_state_dict'], strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we wrap the model in a NeuroBenchModel wrapper. Notice that we use a TorchModel wrapper, rather than and SNNTorchModel wrapper, since the dataset is structured slightly differently. The SNNTorchModel wrapper expects that the timestep dimension of the data is given in dim 1, while the PrimateReaching dataset treats timesteps as samples and gives it in dim 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the model\n",
    "net.reset()\n",
    "model = TorchModel(net) # using TorchModel instead of SNNTorchModel because the SNN iterates over dimension 0\n",
    "model.add_activation_module(snn.SpikingNeuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the execution is the same as before! This should take about a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_metrics = [\"footprint\", \"connection_sparsity\"]\n",
    "workload_metrics = [\"r2\", \"activation_sparsity\", \"synaptic_operations\"]\n",
    "\n",
    "# Benchmark expects the following:\n",
    "benchmark = Benchmark(model, test_set_loader, [], [], [static_metrics, workload_metrics])\n",
    "results = benchmark.run()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected results for SNN:\n",
    "{'footprint': 19648, 'connection_sparsity': 0.0, 'activation_sparsity': 0.9963387091440609, 'r2': 0.6774135828018188, 'synaptic_operations': {'Effective_MACs': 0.0, 'Effective_ACs': 396.6414365765915, 'Dense': 4900.0}}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
